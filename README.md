# projet_seattle
## **Contexte du projet**

Je suisÂ **Data Engineer pour la Ville de Seattle**, qui vise laÂ **neutralitÃ© carbone dâ€™ici 2050**.
La mairie dispose de relevÃ©s de consommation Ã©nergÃ©tique et dâ€™Ã©missions de COâ‚‚ datant deÂ **2016**Â pour desÂ **bÃ¢timents non rÃ©sidentiels**Â (bureaux, Ã©coles, hÃ´tels, etc.).
Lâ€™objectif est deÂ **prÃ©dire les consommations totales dâ€™energie et Ã©missions de COâ‚‚**Â pour les bÃ¢timentsÂ **non encore mesurÃ©s**, Ã  partir de leursÂ **caractÃ©ristiques structurelles**Â :
â¡ï¸ taille, usage, annÃ©e de construction, localisation, etc.

- surface totale,
- nombre dâ€™Ã©tages,
- annÃ©e de construction,
- type dâ€™usage,
- localisation, etc.

---

## ğŸ§© Objectifs du projet

- RÃ©aliser une **analyse exploratoire (EDA)**.
- Nettoyer et prÃ©parer les donnÃ©es (gestion des valeurs manquantes, outliersâ€¦).
- Faire du **feature engineering** (crÃ©ation de nouvelles variables pertinentes).
- Comparer plusieurs **modÃ¨les supervisÃ©s** (rÃ©gression linÃ©aire, Random Forest, SVMâ€¦).
- Optimiser le meilleur modÃ¨le (GridSearchCV).
- **Exposer le modÃ¨le via une API** avec BentoML.

---

## ğŸ—‚ DonnÃ©es

- Nombre de bÃ¢timents (aprÃ¨s filtrage) : **1 624**
- Nombre de variables : ~**40** (structure, localisation, usage, Ã©nergie)

### Principales colonnes utilisÃ©es

- Identification / localisation :
  - `OSEBuildingID`, `City`, `Neighborhood`, `Latitude`, `Longitude`, `ZipCode`, `YearBuilt`
- Structure :
  - `PropertyGFATotal`, `NumberofBuildings`, `NumberofFloors`, `PropertyGFAParking`
- Usage :
  - `BuildingType`, `PrimaryPropertyType`, `LargestPropertyUseTypeGFA`
- Cible :
  - `SiteEnergyUse(kBtu)` (et sa version transformÃ©e `log_SiteEnergyUse`)

---

## ğŸ§¹ Ã‰tape 1 â€“ Analyse exploratoire & nettoyage

### Filtrage des bÃ¢timents

- Conservation des **bÃ¢timents non rÃ©sidentiels** :
  - `NonResidential`, `Nonresidential COS`, `SPS-District K-12`, `Campus`, etc.
- Exclusion des bÃ¢timents Ã  usage **rÃ©sidentiel** :
  - `Multifamily LR`, `MR`, `HR`, `Residence Hall`, `Senior Care Community`, etc.

> RÃ©sultat : **1 624 bÃ¢timents non rÃ©sidentiels** cohÃ©rents avec le pÃ©rimÃ¨tre du projet.

### Valeurs manquantes

- Colonnes trÃ¨s manquantes (`YearsENERGYSTARCertified`, uses secondairesâ€¦) : conservÃ©es dans un premier temps.
- Variables liÃ©es directement aux consommations dÃ©taillÃ©es (`Electricity(kWh)`, etc.) : **supprimÃ©es pour Ã©viter le data leakage**.

### Outliers

- MÃ©thode : IQR sur `PropertyGFATotal` et `SiteEnergyUse(kBtu)`.
- RÃ©sultat :
  - ~12 % de valeurs extrÃªmes sur la surface,
  - ~11 % sur la consommation.
- DÃ©cision : **conserver les outliers**, car ils reprÃ©sentent de gros bÃ¢timents rÃ©alistes (campus, hÃ´pitaux, entrepÃ´ts).

---

## ğŸ§  Ã‰tape 2 â€“ Feature engineering

Nouvelles variables crÃ©Ã©es :

- `BuildingAge` = 2016 - `YearBuilt`  
- `FloorDensity` = `PropertyGFATotal` / `NumberofFloors`
- `HasParking` = 1 si `PropertyGFAParking` > 0, sinon 0
- `GFA_per_building` = `PropertyGFATotal` / `NumberofBuildings`
- `BuildingSizeCategory` = Small / Medium / Large selon `PropertyGFATotal`

Objectif : capturer des informations **structurelles** sans utiliser de donnÃ©es dÃ©pendantes des consommations mesurÃ©es.

---

## âš™ï¸ Ã‰tape 3 â€“ PrÃ©paration des donnÃ©es

- SÃ©paration **train / test** : 80 % / 20 %
- Encodage des variables catÃ©gorielles : **One-Hot Encoding**
- Imputation des valeurs manquantes : **mÃ©diane** pour les variables numÃ©riques
- Mise Ã  lâ€™Ã©chelle : `StandardScaler` pour les modÃ¨les linÃ©aires et SVM
- VÃ©rification de la qualitÃ© des donnÃ©es :
  - absence de `NaN`, `inf`,
  - cohÃ©rence des shapes (X_train, X_test).

---

## ğŸ¤– Ã‰tape 4 â€“ ModÃ©lisation

ModÃ¨les testÃ©s :

- RÃ©gression linÃ©aire
- Random Forest Regressor
- SVM Regressor

MÃ©triques utilisÃ©es :

- RÂ²
- MAE
- RMSE

### Meilleur modÃ¨le : Random Forest

- **RÂ² (test)** â‰ˆ 0.90â€“0.96 (selon la version)
- **MAE** faible
- **RMSE** faible

Le modÃ¨le explique **plus de 90 % de la variance** de la consommation dâ€™Ã©nergie sur le jeu de test.

---

## ğŸ”§ Ã‰tape 5 â€“ API avec BentoML

Le meilleur modÃ¨le (Random Forest) est sauvegardÃ© avec **BentoML** puis exposÃ© via une API.

### Sauvegarde du modÃ¨le

```python
# train_and_save.py
import bentoml
import joblib

model = joblib.load("random_forest_model.pkl")

bento_model = bentoml.sklearn.save_model(
    "energy_rf_pipeline", model
)
